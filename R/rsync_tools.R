#' rsync Hathi Trust EFs from Hathi Trust
#'
#' Given a vector of Hathi Trust IDs (generated, for example, from
#' [workset_builder]), this function attempts to use
#' [rsync](https://en.wikipedia.org/wiki/Rsync) to download their Extracted
#' Features files from Hathi Trust. `rsync` needs to be installed in your system
#' and accessible via [system] or [system2].
#'
#' @param htids A vector of Hathi Trust IDs, usually generated by
#'   [workset_builder].
#' @param dir The directory to save the downloaded EF files to. This defaults to
#'   `getOption("hathiTools.ef.dir")`, which is just  "./hathi-ef" on loading.
#'
#' @return The return code of [system] or [system2] used to run `rsync`, which
#'   must be installed on your system.
#' @export
#'
#' @examples
#' \dontrun{
#' res <- workset_builder(c("tylenol", "paracetamol"), volumes_only = FALSE)
#' rsync_from_hathi(res$htid[1:10])
#' }
rsync_from_hathi <- function(htids, dir = getOption("hathiTools.ef.dir")) {

  hathi_ef_directory <- fs::dir_create(dir)

  tmp <- tempfile(tmpdir = ".", fileext = ".txt")

  suppressMessages(htlinks <- htid_to_rsync(htids, tmp))

  windows <- Sys.info()["sysname"] == "Windows"
  if(!windows) {
    command_args <- paste("-av --files-from",
                          tmp,
                          "data.analytics.hathitrust.org::features-2020.03/",
                          hathi_ef_directory)

    system2("rsync", args = command_args)

  } else {

    command <- paste("rsync -av --files-from",
                     paste0("\'", tmp, "\'"),
                     "data.analytics.hathitrust.org::features-2020.03/",
                     paste0("\'", hathi_ef_directory,
                            "\'"))

    command <- stringr::str_replace_all(command, "\\\\", "/")

    command <- stringr::str_glue('bash -c {shQuote(command)}')

    result <- system(command)
    cat(result, "\n")

  }

  fs::file_delete(tmp)

  result


}

#' Converts a list of htids to relative paths for rsync to download
#'
#' @param htids A character vector or list of HathiTrust ids (htids)
#' @param file A text file to save the resulting list of relative stubbytree
#'   paths to use in the command `rsync -av --files-from FILE.txt
#'   data.analytics.hathitrust.org::features-2020.03/ hathi-ef/`
#'
#' @section Details:
#'
#'   If you have a lot of files to download, generating the list of relative
#'   stubbytree paths and using rsync is much faster than using
#'   [download_hathi_ef] over a list of htids. But rsync only downloads json
#'   files, so calling [get_hathi_counts] will be slower the first time as the
#'   function will cache all downloaded json files to csv.
#'
#' @return The list of relative paths saved to the file (invisibly).
#' @export
#'
#' @examples
#' htid_to_rsync(c("nc01.ark:/13960/t2v41mn4r", "mdp.39015001796443"), tempfile())
htid_to_rsync <- function(htids, file) {
  rel_paths <- htids %>%
    purrr::map_chr(stubby_url_to_rsync)

  writeLines(rel_paths, file)

  message(stringr::str_glue("Use rsync -av --files-from {file} data.analytics.hathitrust.org::features-2020.03/ hathi-ef/ to download EF files to hathi-ef directory"))

  invisible(rel_paths)

}

#' Caches all downloaded JSON Extracted Features files
#'
#' It is useful to run this function after running [rsync_from_hathi]; this way,
#' you can cache all your slow-to-load JSON Extracted Features files to a faster
#' to load format (e.g., feather or csv).
#'
#' @inheritParams get_hathi_counts
#' @param keep_json Whether to keep the downloaded json files. Default is
#'   `TRUE`; if false, it only keeps the local cached files (e.g., the csv
#'   files). This can save space.
#'
#' @export
#'
cache_all <- function(dir = getOption("hathiTools.ef.dir"),
                      cache_type = getOption("hathiTools.cachetype"),
                      keep_json = TRUE) {

  page <- count <- NULL

  cache_type <- match.arg(cache_type, c("csv.gz", "none", "rds",
                                        "feather", "text2vec.csv"))


  if(cache_type == "none") {
    return()
  }

  json_files <- fs::dir_ls(path = dir, recurse = TRUE, glob = "*.json*")
  cached_filenames <- stringr::str_replace(json_files,
                                           "\\.json.+",
                                           paste0(".", cache_type))

  if(length(json_files) < 1) {
    stop("No JSON extracted features files found. Download some from Hathi first!")
  }

  for(local_json in json_files) {
    num_file <- which(json_files %in% local_json)
    if(num_file %% 5 == 1) {
      message("Caching file ", num_file, " of ", length(json_files), "...")
    }
    if(!file.exists(cached_filenames[num_file])) {
      ef <- jsonlite::read_json(local_json) %>%
        parse_listified_book() %>%
        dplyr::mutate(page = as.integer(page),
                      count = as.integer(count))

      cache_ef_file(ef, cached_filenames[num_file], cache_type = cache_type)
    }
  }

  if(!keep_json) {
    message("Now deleting all JSON files!")
    fs::file_delete(json_files)
  }


}


