#' rsync Hathi Trust EFs from Hathi Trust
#'
#' Given a vector of Hathi Trust IDs (generated, for example, from
#' [workset_builder]), this function attempts to use
#' [rsync](https://en.wikipedia.org/wiki/Rsync) to download their Extracted
#' Features (per-page word counts and part of speech information) files from
#' Hathi Trust. `rsync` needs to be installed in your system and accessible via
#' [system] or [system2].
#'
#' @param htids A vector of Hathi Trust IDs, a workset generated by
#'   [workset_builder], or a data frame with a column named 'htid'.
#' @param dir The directory to save the downloaded EF files to. This defaults to
#'   `getOption("hathiTools.ef.dir")`, which is just  "./hathi-ef" on loading.
#'
#' @return The return code of [system] or [system2] used to run `rsync`, which
#'   must be installed on your system.
#' @export
#'
#' @examples
#' \dontrun{
#' res <- workset_builder(c("tylenol", "paracetamol"), volumes_only = FALSE)
#' rsync_from_hathi(res$htid[1:10])
#' }
rsync_from_hathi <- function(htids, dir = getOption("hathiTools.ef.dir")) {

  if("workset_hathi" %in% class(htids)) {
    htids <- htids$htid
  } else if("data.frame" %in% class(htids)) {
    if(!"htid" %in% names(htids)) {
      stop("Cannot find a column named 'htid' in the data frame of htids")
    }
    htids <- htids$htid
  } else {
    if(!is.character(htids)) {
      stop("htids must be a character vector, a workset produced via workset_builder",
           ", or a data frame with a column named 'htid' and containing the htids.")
    }
  }


  hathi_ef_directory <- fs::dir_create(dir)

  tmp <- tempfile(tmpdir = ".", fileext = ".txt")

  suppressMessages(htlinks <- htid_to_rsync(htids, tmp))

  windows <- Sys.info()["sysname"] == "Windows"
  if(!windows) {
    command_args <- paste("-av --files-from",
                          tmp,
                          "data.analytics.hathitrust.org::features-2020.03/",
                          hathi_ef_directory)

    system2("rsync", args = command_args)

  } else {

    command <- paste("rsync -av --files-from",
                     paste0("\'", tmp, "\'"),
                     "data.analytics.hathitrust.org::features-2020.03/",
                     paste0("\'", hathi_ef_directory,
                            "\'"))

    command <- stringr::str_replace_all(command, "\\\\", "/")

    command <- stringr::str_glue('bash -c {shQuote(command)}')

    result <- system(command)
    cat(result, "\n")

  }

  fs::file_delete(tmp)

  result


}

#' Converts a list of htids to relative paths for rsync to download
#'
#' @param htids A character vector or list of HathiTrust ids (htids), a workset
#'   generated by [workset_builder], or a data frame with a column named 'htid'
#'   and containing the htids.
#' @param file A text file to save the resulting list of relative stubbytree
#'   paths to use in the command `rsync -av --files-from FILE.txt
#'   data.analytics.hathitrust.org::features-2020.03/ hathi-ef/`
#'
#' @section Details:
#'
#'   If you have a lot of files to download, generating the list of relative
#'   stubbytree paths and using rsync is much faster than using
#'   [get_hathi_counts] over a list of htids. But rsync only downloads json
#'   files, so calling [get_hathi_counts] on a downloaded json file will be
#'   slower the first time as the function will cache the json file to csv. It
#'   is best to run [cache_htids] after using rsync to reduce this performance
#'   penalty.
#'
#' @return The list of relative paths saved to the file (invisibly).
#' @export
#'
#' @examples
#' htid_to_rsync(c("nc01.ark:/13960/t2v41mn4r", "mdp.39015001796443"), tempfile())
htid_to_rsync <- function(htids, file) {
  if("workset_hathi" %in% class(htids)) {
    htids <- htids$htid
  } else if("data.frame" %in% class(htids)) {
    if(!"htid" %in% names(htids)) {
      stop("Cannot find a column named 'htid' in the data frame of htids")
    }
    htids <- htids$htid
  } else {
    if(!is.character(htids)) {
      stop("htids must be a character vector, a workset produced via workset_builder",
           ", or a data frame with a column named 'htid' and containing the htids.")
    }
  }

  rel_paths <- htids %>%
    purrr::map_chr(stubby_url_to_rsync)

  writeLines(rel_paths, file)

  message(stringr::str_glue("Use rsync -av --files-from {file} data.analytics.hathitrust.org::features-2020.03/ hathi-ef/ to download EF files to hathi-ef directory"))

  invisible(rel_paths)

}

#' Caches downloaded JSON Extracted Features files to another format
#'
#' It is useful to run this function after running [rsync_from_hathi]; this way,
#' you can cache all your slow-to-load JSON Extracted Features files to a faster
#' to load format (e.g., `feather` or `csv`).
#'
#' @param htids A character vector of Hathi Trust ids, a workset created with
#'   [workset_builder], or a data frame with a column named "htid" containing
#'   the Hathi Trust ids that require caching.
#' @inheritParams get_hathi_counts
#' @param keep_json Whether to keep the downloaded json files. Default is
#'   `TRUE`; if false, it only keeps the local cached files (e.g., the csv
#'   files) and deletes the associated JSON files. This can save space.
#'
#' @return A [tibble] with the paths of the cached files and an indicator of
#'   whether each htid was successfully cached.
#'
#' @export
cache_htids <- function(htids,
                        dir = getOption("hathiTools.ef.dir"),
                        cache_type = getOption("hathiTools.cachetype"),
                        keep_json = TRUE) {

  exists.y <- exists.x <- page <- count <- NULL

  cache_type <- match.arg(cache_type, c("csv.gz", "none", "rds",
                                        "feather", "text2vec.csv"))

  if("workset_hathi" %in% class(htids)) {
    htids <- htids$htid
  } else if("data.frame" %in% class(htids)) {
    if(!"htid" %in% names(htids)) {
      stop("Cannot find a column named 'htid' in the data frame of htids")
    }
    htids <- htids$htid
  } else if(!is.character(htids)) {
    stop("htids must be a character vector, a workset produced via workset_builder",
         ", or a data frame with a column named 'htid' and containing the htids.")

  }

  json_file_locs <-  find_cached_htids(htids,
                                       dir = dir,
                                       cache_type = "none")

  if(cache_type == "none") {
    message("No files cached. Returning JSON EF file locations.")
    return(json_file_locs)
  }

  cached_file_locs <- find_cached_htids(htids,
                                        dir = dir,
                                        cache_type = cache_type)

  to_cache <- cached_file_locs %>%
    dplyr::left_join(json_file_locs, by = "htid") %>%
    dplyr::filter(!exists.x, exists.y)

  if(nrow(to_cache) == 0) {
    non_existent_json <- cached_file_locs %>%
      dplyr::left_join(json_file_locs, by = "htid") %>%
      dplyr::filter(!exists.y) %>%
      nrow()

    cached_already <- cached_file_locs %>%
      dplyr::left_join(json_file_locs, by = "htid") %>%
      dplyr::filter(exists.x) %>%
      nrow()

    if(non_existent_json > 0) {
      message("No HTIDs can be cached, since their JSON EF files have not been downloaded yet to ", dir)
      message("Try using rsync_from_hathi(htids) to download them.")
    }
    if(cached_already > 0) {
      message("All HTIDs have already been cached to ", cache_type, " format.")
      message("Returning data frame with file locations.")
    }
    if(!keep_json) {
      message("Now deleting associated JSON files!")
      fs::file_delete(json_file_locs$local_loc)
    }
    return(find_cached_htids(htids, dir = dir, cache_type = cache_type))
  }

  if(nrow(to_cache) > 0 && nrow(to_cache) < nrow(cached_file_locs)) {
    message("Some files have already been cached. Caching the rest.")
  }

  json_files <- to_cache$local_loc.y[to_cache$exists.y]
  for(local_json in json_files) {
    num_file <- which(json_files %in% local_json)
    if(num_file %% 5 == 1) {
      message("Caching ", local_json, " to ", cache_type,
              ", file ", num_file, " of ", length(json_files), "...")
    }
    ef <- jsonlite::read_json(local_json) %>%
      parse_listified_book() %>%
      dplyr::mutate(page = as.integer(page),
                    count = as.integer(count))

    cache_ef_file(ef, to_cache$local_loc.x[num_file], cache_type = cache_type)
  }

  if(!keep_json) {
    message("Now deleting associated JSON files!")
    fs::file_delete(json_file_locs$local_loc)
  }

  find_cached_htids(htids, dir = dir, cache_type = cache_type)

}


#' Finds cached Extracted Features files for a set of HT ids
#'
#' @param htids A character vector of Hathi Trust ids, a workset created with
#'   [workset_builder], or a data frame with a column named "htid" containing
#'   the Hathi Trust ids that require caching.
#' @inheritParams get_hathi_counts
#'
#' @return A [tibble] with the paths of the cached files and an indicator of
#'   whether each htid has an existing cached file.
#'
#' @export
find_cached_htids <- function(htids,
                              dir = getOption("hathiTools.ef.dir"),
                              cache_type = getOption("hathiTools.cachetype")) {
  cache_type <- match.arg(cache_type, c("csv.gz", "none", "rds",
                                        "feather", "text2vec.csv"))

  if("workset_hathi" %in% class(htids)) {
    htids <- htids$htid
  } else if("data.frame" %in% class(htids)) {
    if(!"htid" %in% names(htids)) {
      stop("Cannot find a column named 'htid' in the data frame of htids")
    }
    htids <- htids$htid
  } else if(!is.character(htids)) {
      stop("htids must be a character vector, a workset produced via workset_builder",
           ", or a data frame with a column named 'htid' and containing the htids.")

  }



  if(cache_type == "none") {
    cache_type <- "json.bz2"
  }

  local_files <- htids %>%
    purrr::map_chr(local_loc, suffix = cache_type, dir = dir)

  tibble(htid = htids, local_loc = local_files, exists = fs::file_exists(local_files))



}
